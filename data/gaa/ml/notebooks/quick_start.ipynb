{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e81253",
   "metadata": {},
   "source": [
    "# GAA Budget Machine Learning - Quick Start\n",
    "\n",
    "This notebook demonstrates how to use the ML pipeline for budget analysis.\n",
    "\n",
    "## Contents\n",
    "1. Load and explore data\n",
    "2. Feature engineering\n",
    "3. Train models\n",
    "4. Generate predictions\n",
    "5. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021777f",
   "metadata": {},
   "source": [
    "## 1. Load GAA Budget Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b312fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset\n",
    "df = pd.read_parquet('../../gaa.parquet')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Years available: {sorted(df['year'].unique())}\")\n",
    "print(f\"Total budget: ₱{df['amt'].sum():,.2f}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f218ffaf",
   "metadata": {},
   "source": [
    "## 2. Explore Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget by year\n",
    "yearly_budget = df.groupby('year')['amt'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(yearly_budget['year'], yearly_budget['amt'] / 1e12)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Budget (Trillion ₱)')\n",
    "plt.title('Total Budget by Year')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Top departments\n",
    "plt.subplot(1, 2, 2)\n",
    "top_depts = df.groupby('uacs_dpt_dsc')['amt'].sum().nlargest(10)\n",
    "top_depts.plot(kind='barh')\n",
    "plt.xlabel('Budget (₱)')\n",
    "plt.title('Top 10 Departments')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23296e31",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Run the feature engineering script to create ML-ready features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run the feature engineering script from here\n",
    "# Or use the command line: python ../features/feature_engineering.py\n",
    "\n",
    "# Load engineered features if already created\n",
    "features_path = Path('../features/budget_features.parquet')\n",
    "\n",
    "if features_path.exists():\n",
    "    df_features = pd.read_parquet(features_path)\n",
    "    print(f\"Loaded features: {df_features.shape}\")\n",
    "    print(f\"New features added: {df_features.shape[1] - df.shape[1]}\")\n",
    "    \n",
    "    # Show sample of new features\n",
    "    new_cols = [col for col in df_features.columns if col not in df.columns]\n",
    "    print(f\"\\nNew feature columns: {new_cols[:10]}...\")\n",
    "else:\n",
    "    print(\"Features not yet generated. Run: python ../features/feature_engineering.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34906c84",
   "metadata": {},
   "source": [
    "## 4. View Model Results\n",
    "\n",
    "Load and visualize trained model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load forecast predictions\n",
    "predictions_dir = Path('../predictions')\n",
    "\n",
    "if predictions_dir.exists():\n",
    "    # Find latest forecast file\n",
    "    forecast_files = list(predictions_dir.glob('budget_forecast_*.parquet'))\n",
    "    \n",
    "    if forecast_files:\n",
    "        latest_forecast = sorted(forecast_files)[-1]\n",
    "        df_forecast = pd.read_parquet(latest_forecast)\n",
    "        \n",
    "        print(f\"Loaded forecast: {latest_forecast.name}\")\n",
    "        print(f\"Predictions shape: {df_forecast.shape}\")\n",
    "        print(f\"Total predicted budget: ₱{df_forecast['predicted_amt'].sum():,.2f}\")\n",
    "        \n",
    "        df_forecast.head()\n",
    "    else:\n",
    "        print(\"No forecast files found\")\n",
    "else:\n",
    "    print(\"Predictions directory not found. Run the ML pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anomaly detection results\n",
    "anomaly_files = list(predictions_dir.glob('anomalies_*.parquet'))\n",
    "\n",
    "if anomaly_files:\n",
    "    latest_anomalies = sorted(anomaly_files)[-1]\n",
    "    df_anomalies = pd.read_parquet(latest_anomalies)\n",
    "    \n",
    "    print(f\"Loaded anomalies: {latest_anomalies.name}\")\n",
    "    print(f\"Number of anomalies: {len(df_anomalies)}\")\n",
    "    \n",
    "    # Plot anomaly distribution\n",
    "    if 'anomaly_type' in df_anomalies.columns:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        df_anomalies['anomaly_type'].value_counts().plot(kind='bar')\n",
    "        plt.xlabel('Anomaly Type')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Anomaly Detection Results')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    df_anomalies.head()\n",
    "else:\n",
    "    print(\"No anomaly files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustering results\n",
    "cluster_files = list(predictions_dir.glob('spending_clusters_*.parquet'))\n",
    "\n",
    "if cluster_files:\n",
    "    latest_clusters = sorted(cluster_files)[-1]\n",
    "    df_clusters = pd.read_parquet(latest_clusters)\n",
    "    \n",
    "    print(f\"Loaded clusters: {latest_clusters.name}\")\n",
    "    print(f\"Number of entities clustered: {len(df_clusters)}\")\n",
    "    \n",
    "    # Plot cluster distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_clusters['cluster_label'].value_counts().plot(kind='bar')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Cluster Distribution')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # PCA visualization if available\n",
    "    if 'pca_1' in df_clusters.columns and 'pca_2' in df_clusters.columns:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        scatter = plt.scatter(df_clusters['pca_1'], df_clusters['pca_2'], \n",
    "                            c=df_clusters['cluster_id'], cmap='viridis', alpha=0.6)\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.title('Cluster Visualization (PCA)')\n",
    "        plt.colorbar(scatter, label='Cluster ID')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    df_clusters.head()\n",
    "else:\n",
    "    print(\"No cluster files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e4d2b2",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "- Experiment with different model parameters\n",
    "- Add custom features based on domain knowledge\n",
    "- Integrate predictions into the dashboard\n",
    "- Set up automated retraining pipeline\n",
    "- Create custom visualizations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
